{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bangla-Abbusive.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bangla</th>\n",
       "      <th>English</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Categry</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>????? ???? ????? ????? ???? ??? ??? ???? ?????...</td>\n",
       "      <td>Islam cannot be a religion that has to be save...</td>\n",
       "      <td>Hate towards religion</td>\n",
       "      <td>Religious</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>????? ???????? ???????? ????????</td>\n",
       "      <td>Shamim Patwari Congratulations Bangladesh</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Sports</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>???????? ???????? ??????? ?????, ?????? ??? ??...</td>\n",
       "      <td>Congratulations to Bangladesh cricket team, we...</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Sports</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>?????? ??????????, ???????, ????????? ????? ??...</td>\n",
       "      <td>Please do not catch rickshaw pullers, day labo...</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>??? ???? ????? ?????????? ????? ??????? ????</td>\n",
       "      <td>It was very painful to see  the rickshaw pulle...</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Bangla  \\\n",
       "0  ????? ???? ????? ????? ???? ??? ??? ???? ?????...   \n",
       "1                   ????? ???????? ???????? ????????   \n",
       "2  ???????? ???????? ??????? ?????, ?????? ??? ??...   \n",
       "3  ?????? ??????????, ???????, ????????? ????? ??...   \n",
       "4       ??? ???? ????? ?????????? ????? ??????? ????   \n",
       "\n",
       "                                             English                 Reason  \\\n",
       "0  Islam cannot be a religion that has to be save...  Hate towards religion   \n",
       "1          Shamim Patwari Congratulations Bangladesh        Normal Sentence   \n",
       "2  Congratulations to Bangladesh cricket team, we...        Normal Sentence   \n",
       "3  Please do not catch rickshaw pullers, day labo...        Normal Sentence   \n",
       "4  It was very painful to see  the rickshaw pulle...        Normal Sentence   \n",
       "\n",
       "     Categry Label  \n",
       "0  Religious   Yes  \n",
       "1     Sports    No  \n",
       "2     Sports    No  \n",
       "3      Other    No  \n",
       "4      Other    No  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Religious', 'Sports', 'Other', 'Personal', 'Geopolitical',\n",
       "       'Political', 'Gender', 'Sports ', 'Reliigious', 'Others',\n",
       "       'Personal '], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Categry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bangla     0\n",
       "English    1\n",
       "Reason     1\n",
       "Categry    0\n",
       "Label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bangla     0\n",
       "English    0\n",
       "Reason     0\n",
       "Categry    0\n",
       "Label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combine'] = df.English.str.cat(df['Reason'],\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'May the personal security of our very popular, best young MP of the country not be disturbed. That too needs to be seen. Normal Sentence'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Combine'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing\n",
    "lemma = WordNetLemmatizer()\n",
    "def textpreprocess(text):\n",
    "    Comment = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    Comment = Comment.lower()\n",
    "    Comment = Comment.split()\n",
    "    Comment = [lemma.lemmatize(word) for word in Comment if word not in set(stopwords.words('english'))]\n",
    "    Comment = ' '.join(Comment)\n",
    "    \n",
    "    return Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th taste pasta served yesterday'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textpreprocess('£££@=@/// 100th 200 Did you taste the pasta that served yesterday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['English'] = df['English'].apply(textpreprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'may personal security popular best young mp country disturbed need seen'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['English'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Label'] = le.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bangla</th>\n",
       "      <th>English</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Categry</th>\n",
       "      <th>Label</th>\n",
       "      <th>Combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>????? ???? ????? ????? ???? ??? ??? ???? ?????...</td>\n",
       "      <td>islam cannot religion saved killing people</td>\n",
       "      <td>Hate towards religion</td>\n",
       "      <td>Religious</td>\n",
       "      <td>1</td>\n",
       "      <td>Islam cannot be a religion that has to be save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>????? ???????? ???????? ????????</td>\n",
       "      <td>shamim patwari congratulation bangladesh</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>Shamim Patwari Congratulations Bangladesh Norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>???????? ???????? ??????? ?????, ?????? ??? ??...</td>\n",
       "      <td>congratulation bangladesh cricket team play ma...</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>Congratulations to Bangladesh cricket team, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>?????? ??????????, ???????, ????????? ????? ??...</td>\n",
       "      <td>please catch rickshaw puller day laborer worke...</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Please do not catch rickshaw pullers, day labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>??? ???? ????? ?????????? ????? ??????? ????</td>\n",
       "      <td>painful see rickshaw puller uncle screaming</td>\n",
       "      <td>Normal Sentence</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>It was very painful to see  the rickshaw pulle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Bangla  \\\n",
       "0  ????? ???? ????? ????? ???? ??? ??? ???? ?????...   \n",
       "1                   ????? ???????? ???????? ????????   \n",
       "2  ???????? ???????? ??????? ?????, ?????? ??? ??...   \n",
       "3  ?????? ??????????, ???????, ????????? ????? ??...   \n",
       "4       ??? ???? ????? ?????????? ????? ??????? ????   \n",
       "\n",
       "                                             English                 Reason  \\\n",
       "0         islam cannot religion saved killing people  Hate towards religion   \n",
       "1           shamim patwari congratulation bangladesh        Normal Sentence   \n",
       "2  congratulation bangladesh cricket team play ma...        Normal Sentence   \n",
       "3  please catch rickshaw puller day laborer worke...        Normal Sentence   \n",
       "4        painful see rickshaw puller uncle screaming        Normal Sentence   \n",
       "\n",
       "     Categry  Label                                            Combine  \n",
       "0  Religious      1  Islam cannot be a religion that has to be save...  \n",
       "1     Sports      0  Shamim Patwari Congratulations Bangladesh Norm...  \n",
       "2     Sports      0  Congratulations to Bangladesh cricket team, we...  \n",
       "3      Other      0  Please do not catch rickshaw pullers, day labo...  \n",
       "4      Other      0  It was very painful to see  the rickshaw pulle...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "Vector = TfidfVectorizer()\n",
    "X = Vector.fit_transform(df['English'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = list()\n",
    "Accuracy = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "F1score = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(clf_model, X_test, y_test, algo=None):\n",
    "    # Test set prediction\n",
    "    #y_prob=clf_model.predict_proba(X_test)\n",
    "    y_pred=clf_model.predict(X_test)\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print('='*60)\n",
    "    print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print('='*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\")\n",
    "    print('Accuracy Score')\n",
    "    print('='*60)\n",
    "    print(clf_model.score(X_test, y_test))\n",
    "          \n",
    "    model.append(algo)\n",
    "    Accuracy.append(clf_model.score(X_test, y_test))\n",
    "    precision.append(precision_score(y_test,y_pred))\n",
    "    recall.append(recall_score(y_test,y_pred))\n",
    "    F1score.append(f1_score(y_test,y_pred))\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudhakor Das\\anaconda3\\envs\\translator\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.93294362        nan 0.9311192         nan 0.93294362\n",
      "        nan 0.9311192         nan 0.9311192         nan 0.9311192\n",
      "        nan 0.93064073        nan 0.9311192         nan 0.93064073\n",
      "        nan 0.9311192         nan 0.9311192         nan 0.9311192\n",
      "        nan 0.9311192         nan 0.9311192         nan 0.9311192\n",
      "        nan 0.9311192         nan 0.9311192         nan 0.9311192\n",
      "        nan 0.9311192         nan 0.9311192         nan 0.93064073\n",
      "        nan 0.93064073        nan 0.93109528        nan 0.93109528\n",
      "        nan 0.93248908        nan 0.93248908        nan 0.93428334\n",
      "        nan 0.93428334        nan 0.93385271        nan 0.93385271]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.6378937069540613)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "params={'C':np.logspace( -10, 1, 15),'class_weight':[None,'balanced'],'penalty':['l1','l2']}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf_LR = GridSearchCV(log_model, params, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[31 20]\n",
      " [ 4 35]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.61      0.72        51\n",
      "           1       0.64      0.90      0.74        39\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.76      0.75      0.73        90\n",
      "weighted avg       0.78      0.73      0.73        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.9069884364002011\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888888888888889"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[32 19]\n",
      " [ 4 35]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.74        51\n",
      "           1       0.65      0.90      0.75        39\n",
      "\n",
      "    accuracy                           0.74        90\n",
      "   macro avg       0.77      0.76      0.74        90\n",
      "weighted avg       0.78      0.74      0.74        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.7444444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_MB = MultinomialNB()\n",
    "clf_MB.fit(X_train,y_train)\n",
    "test_eval(clf_MB, X_test, y_test, 'MultinomialNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [2,10,30,50,100]\n",
    "# Maximum number of depth in each tree:\n",
    "max_depth = [i for i in range(5,16,2)]\n",
    "# Minimum number of samples to consider to split a node:\n",
    "min_samples_split = [2, 5, 10, 15, 20, 50, 100]\n",
    "# Minimum number of samples to consider at each leaf node:\n",
    "min_samples_leaf = [1, 2, 5]\n",
    "#Impurity\n",
    "criterion = ['gini', 'entropy']\n",
    "#The number of features to consider when looking for the best split\n",
    "max_features = ['log2', 'sqrt', 'auto']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=11, max_features='sqrt', min_samples_split=20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_param_grid = { \n",
    "    'max_features':max_features,\n",
    "    'criterion':criterion,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "clf_DT = RandomizedSearchCV(tree_model, tree_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "clf_DT.fit(X_train, y_train)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[ 3 48]\n",
      " [ 0 39]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11        51\n",
      "           1       0.45      1.00      0.62        39\n",
      "\n",
      "    accuracy                           0.47        90\n",
      "   macro avg       0.72      0.53      0.37        90\n",
      "weighted avg       0.76      0.47      0.33        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.5460030165912518\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444444444444445"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Random forest CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_params={'n_estimators':estimators,\n",
    "           'max_features':max_features,\n",
    "           'criterion':criterion,\n",
    "           'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "clf_RF = RandomizedSearchCV(rf_model, rf_params, cv=cv, scoring='roc_auc', n_jobs=-1, n_iter=20, verbose=2)\n",
    "clf_RF.fit(X_train, y_train)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[18 33]\n",
      " [ 2 37]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.35      0.51        51\n",
      "           1       0.53      0.95      0.68        39\n",
      "\n",
      "    accuracy                           0.61        90\n",
      "   macro avg       0.71      0.65      0.59        90\n",
      "weighted avg       0.74      0.61      0.58        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.8838612368024134\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[35 16]\n",
      " [ 5 34]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77        51\n",
      "           1       0.68      0.87      0.76        39\n",
      "\n",
      "    accuracy                           0.77        90\n",
      "   macro avg       0.78      0.78      0.77        90\n",
      "weighted avg       0.79      0.77      0.77        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_SVC = SVC(kernel = 'sigmoid', gamma = 1.0)\n",
    "clf_SVC.fit(X_train, y_train)\n",
    "test_eval(clf_SVC, X_test, y_test, 'Support Vector Machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[25 26]\n",
      " [ 3 36]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.49      0.63        51\n",
      "           1       0.58      0.92      0.71        39\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.74      0.71      0.67        90\n",
      "weighted avg       0.76      0.68      0.67        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ada=AdaBoostClassifier()\n",
    "clf_ada.fit(X_train, y_train)\n",
    "test_eval(clf_ada, X_test, y_test, 'AdaBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, max_depth=15, min_samples_leaf=2,\n",
       "                           min_samples_split=20, n_estimators=50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "gb_params = { \n",
    "    \"n_estimators\":[1,3,5,10,15,20,30,40,50,],\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "clf_gb=RandomizedSearchCV(gb_model,gb_params,cv=cv, scoring='roc_auc',n_jobs=1)\n",
    "\n",
    "clf_gb.fit(X_train, y_train)\n",
    "clf_gb.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[21 30]\n",
      " [ 2 37]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.41      0.57        51\n",
      "           1       0.55      0.95      0.70        39\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.73      0.68      0.63        90\n",
      "weighted avg       0.76      0.64      0.62        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.8619909502262444\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_gb, X_test, y_test, 'GradientBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.1, loss='modified_huber')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_params = {\n",
    "    \"loss\" : [ \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "clf_sgd=RandomizedSearchCV(sgd_model,sgd_params,cv=cv, scoring='roc_auc',n_jobs=1)\n",
    "\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "clf_sgd.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[21 30]\n",
      " [ 2 37]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.41      0.57        51\n",
      "           1       0.55      0.95      0.70        39\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.73      0.68      0.63        90\n",
      "weighted avg       0.76      0.64      0.62        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.8979386626445449\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_sgd, X_test, y_test, 'SGDClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[21 30]\n",
      " [ 2 37]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.41      0.57        51\n",
      "           1       0.55      0.95      0.70        39\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.73      0.68      0.63        90\n",
      "weighted avg       0.76      0.64      0.62        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf_ETC = ExtraTreesClassifier()\n",
    "clf_ETC.fit(X_train, y_train)\n",
    "test_eval(clf_ETC, X_test, y_test, 'ExtraTreesClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.KNeighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[37 14]\n",
      " [ 8 31]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77        51\n",
      "           1       0.69      0.79      0.74        39\n",
      "\n",
      "    accuracy                           0.76        90\n",
      "   macro avg       0.76      0.76      0.75        90\n",
      "weighted avg       0.76      0.76      0.76        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_KNC = KNeighborsClassifier()\n",
    "clf_KNC.fit(X_train, y_train)\n",
    "test_eval(clf_KNC, X_test, y_test, 'KNeighbours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[35 16]\n",
      " [ 4 35]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78        51\n",
      "           1       0.69      0.90      0.78        39\n",
      "\n",
      "    accuracy                           0.78        90\n",
      "   macro avg       0.79      0.79      0.78        90\n",
      "weighted avg       0.81      0.78      0.78        90\n",
      " \n",
      "\n",
      "Accuracy Score\n",
      "============================================================\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp  = MLPClassifier()\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "test_eval(clf_mlp, X_test, y_test, 'MLPClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9069884364002011,\n",
       " 0.7444444444444445,\n",
       " 0.5460030165912518,\n",
       " 0.8838612368024134,\n",
       " 0.7666666666666667,\n",
       " 0.6777777777777778,\n",
       " 0.8619909502262444,\n",
       " 0.8979386626445449,\n",
       " 0.6444444444444445,\n",
       " 0.7555555555555555,\n",
       " 0.7777777777777778]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_eval_df = pd.DataFrame({'Model':model,\n",
    "                            'Accuracy':Accuracy,\n",
    "                            'Precision':precision,\n",
    "                            'Recall':recall,\n",
    "                            'F1-score':F1score,\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.906988</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.752688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.546003</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.883861</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.678899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.764045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.712871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>0.861991</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.897939</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighbours</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy  Precision    Recall  F1-score\n",
       "0      Logistic Regression  0.906988   0.636364  0.897436  0.744681\n",
       "1            MultinomialNB  0.744444   0.648148  0.897436  0.752688\n",
       "2            Decision Tree  0.546003   0.448276  1.000000  0.619048\n",
       "3            Random Forest  0.883861   0.528571  0.948718  0.678899\n",
       "4   Support Vector Machine  0.766667   0.680000  0.871795  0.764045\n",
       "5                 AdaBoost  0.677778   0.580645  0.923077  0.712871\n",
       "6            GradientBoost  0.861991   0.552239  0.948718  0.698113\n",
       "7            SGDClassifier  0.897939   0.552239  0.948718  0.698113\n",
       "8     ExtraTreesClassifier  0.644444   0.552239  0.948718  0.698113\n",
       "9              KNeighbours  0.755556   0.688889  0.794872  0.738095\n",
       "10           MLPClassifier  0.777778   0.686275  0.897436  0.777778"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_eval_df.to_csv('Bigram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_mlp, open('model-mlp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Vector,open('vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
